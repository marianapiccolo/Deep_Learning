{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "034f8527",
   "metadata": {},
   "source": [
    "# Recurrent Networks for Textual Data Processing <br>\n",
    "Loading the necessary packages <br>\n",
    "Loading the data (IMDB dataset)<br>\n",
    "Development of a Vanilla RNN model<br>\n",
    "Development of a Bidirectional LSTM RNN model<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a88d6bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.layers import SimpleRNN, Dense, Activation, Embedding, LSTM, Bidirectional\n",
    "from keras.utils import pad_sequences\n",
    "from keras.datasets import imdb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d6f408",
   "metadata": {},
   "source": [
    "# Loading the data (IMDB)\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb/load_data\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8f3f7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,Y_train), (X_test, Y_test) = imdb.load_data(path = \"imdb.npz\",\n",
    "                                    num_words = None,\n",
    "                                    skip_top = 0,\n",
    "                                    maxlen = None,\n",
    "                                    seed = 113,\n",
    "                                    start_char = 1,\n",
    "                                    oov_char = 2,\n",
    "                                    index_from = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d62b68aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (25000,)\n",
      "Y_train:  (25000,)\n",
      "X_test:  (25000,)\n",
      "Y_test:  (25000,)\n",
      "Existing classes:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train: \",X_train.shape)\n",
    "print(\"Y_train: \",Y_train.shape)\n",
    "print(\"X_test: \",X_test.shape)\n",
    "print(\"Y_test: \",Y_test.shape)\n",
    "\n",
    "print(\"Existing classes: \", np.unique(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84d713ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution (training):  {0: 12500, 1: 12500}\n"
     ]
    }
   ],
   "source": [
    "unique,  cc = np.unique(Y_train, return_counts = True)\n",
    "print(\"Class distribution (training): \", dict(zip(unique,cc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c90ee2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution (test):  {0: 12500, 1: 12500}\n"
     ]
    }
   ],
   "source": [
    "unique,  cc = np.unique(Y_test, return_counts = True)\n",
    "print(\"Class distribution (test): \", dict(zip(unique,cc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b9d3e6",
   "metadata": {},
   "source": [
    "# Examples of Reviews (Sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81f02de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the dictionary:  88584\n"
     ]
    }
   ],
   "source": [
    "# obtaining the dictionary (id --> word)\n",
    "dictionary = imdb.get_word_index() \n",
    "num_words = len(dictionary) \n",
    "print(\"Total number of words in the dictionary: \", num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8751a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 i\n",
      "9 it\n",
      "6 is\n",
      "8 in\n",
      "4 of\n",
      "3 a\n",
      "7 br\n",
      "1 the\n",
      "2 and\n",
      "5 to\n"
     ]
    }
   ],
   "source": [
    "# Some words (10 most frequent)\n",
    "for (word, id) in dictionary.items(): \n",
    "    if id <= 10: print(id, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab9db5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decode(idx = 1):\n",
    "    reverse_index = dict([(id,word) for (word, id) in dictionary.items()])\n",
    "    sentence = \" \".join([reverse_index.get(i - 3, \"!\") for i in X_train[idx]])\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab053ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ids:  [   -2   775   125    71     9   627   160    12     1  1763  7979  1048\n",
      " 43219    29    82   153    42    37   145   136   118   661   662     7\n",
      "     7  1358   170     1   746 86585    13  3801     5     1   223    62\n",
      "     9    40   124    21 15341     7     7]\n",
      "Sentence:  ! begins better than it ends funny that the russian submarine crew outperforms all other actors it's like those scenes where documentary shots br br spoiler part the message dechifered was contrary to the whole story it just does not mesh br br\n",
      "Length:  43\n",
      "Class:  0\n"
     ]
    }
   ],
   "source": [
    "# Example of sentence (ids)\n",
    "idx = 5 \n",
    "sentence = Decode(idx) \n",
    "print(\"Ids: \", np.array(X_train[idx])-3) # subtraction of 3 - initial encoding \n",
    "print(\"Sentence: \", sentence) \n",
    "print(\"Length: \", len(X_train[idx])) \n",
    "print(\"Class: \", Y_train[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0f012",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Padding, dictionary reduction, and embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c734d0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing the number of words in the dictionary\n",
    "# to reduce the number of parameters in the model\n",
    "num_words = 5000\n",
    "(X_train, Y_train), (X_test, Y_test) = imdb.load_data(num_words=num_words)\n",
    "\n",
    "maxlen = 100 \n",
    "embedding = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61feb99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    1  778  128   74   12  630  163   15    4 1766    2 1051    2\n",
      "   32   85  156   45   40  148  139  121  664  665   10   10 1361  173\n",
      "    4  749    2   16 3804    8    4  226   65   12   43  127   24    2\n",
      "   10   10]\n"
     ]
    }
   ],
   "source": [
    "# Maximum sentence length\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "print(X_train[5])\n",
    "decoded_review = Decode(5)\n",
    "\n",
    "# Words outside the dictionary (absent | >num_words)\n",
    "# are replaced by oov_char (2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
